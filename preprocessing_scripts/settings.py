#Settings for how tokenization is performed, for the dictionary, index, and for query terms
normalize = 1
fully_normalize = 1 
remove_units = 1
remove_stopwords = 1 
fully_lower = 1
stem = 1